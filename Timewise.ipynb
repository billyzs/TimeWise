{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V4qBQ0fuSqz6"
      },
      "outputs": [],
      "source": [
        "#@markdown ## ⚠️ PLEASE NOTE:\n",
        "#@markdown This colab runs best using a GPU runtime.  From the Colab menu, choose Runtime > Change Runtime Type, then select **'GPU'** in the dropdown.\n",
        "\n",
        "import functools\n",
        "import jax\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "from jax import numpy as jp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import HTML, clear_output\n",
        "\n",
        "try:\n",
        "  import brax\n",
        "except ImportError:\n",
        "  !pip install git+https://github.com/google/brax.git@main\n",
        "  clear_output()\n",
        "  import brax\n",
        "\n",
        "try:\n",
        "  import wandb\n",
        "except:\n",
        "  !pip install wandb\n",
        "  clear_output()\n",
        "  import wandb\n",
        "  \n",
        "import flax\n",
        "from brax import envs\n",
        "from brax.io import model\n",
        "from brax.io import json\n",
        "from brax.io import html\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from brax.training.agents.sac import train as sac\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  from jax.tools import colab_tpu\n",
        "  colab_tpu.setup_tpu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = {\n",
        "        \"num_timesteps\":50000000,\n",
        "        \"num_evals\":10,\n",
        "        \"reward_scaling\":0.1,\n",
        "        \"episode_length\":1000,\n",
        "        \"normalize_observations\":True,\n",
        "        \"action_repeat\":1,\n",
        "        \"unroll_length\":10,\n",
        "        \"num_minibatches\":32,\n",
        "        \"num_updates_per_batch\":8,\n",
        "        \"discounting\":0.97,\n",
        "        \"learning_rate\":3e-4,\n",
        "        \"entropy_cost\":1e-3,\n",
        "        \"num_envs\":2048,\n",
        "        \"batch_size\":1024,\n",
        "        \"seed\": 0xdeadbeef,\n",
        "    }"
      ],
      "metadata": {
        "id": "26tH5gss5tTi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "VESus-aQTSzc",
        "outputId": "5daa078b-22d2-4955-e9f2-72dca1586e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Starting\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monatv\u001b[0m (\u001b[33me1even\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230504_181232-235rbvsh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/e1even/timewise/runs/235rbvsh' target=\"_blank\">humanoid_ppo_trial</a></strong> to <a href='https://wandb.ai/e1even/timewise' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/e1even/timewise' target=\"_blank\">https://wandb.ai/e1even/timewise</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/e1even/timewise/runs/235rbvsh' target=\"_blank\">https://wandb.ai/e1even/timewise/runs/235rbvsh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import logging\n",
        "\n",
        "# import gin\n",
        "#os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=16'\n",
        "import jax\n",
        "\n",
        "from datetime import datetime\n",
        "from jax import numpy as jp\n",
        "import brax\n",
        "\n",
        "import flax\n",
        "from brax import envs\n",
        "from brax.io import model\n",
        "from brax.io import json\n",
        "from brax.io import html\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from brax.training.agents.sac import train as sac\n",
        "from brax.training.agents.apg import train as apg\n",
        "import wandb\n",
        "\n",
        "\n",
        "wandb_init = wandb.init\n",
        "cpu_device = jax.devices(\"cpu\")[0]\n",
        "\n",
        "logger = logging.getLogger('my_logger')\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, # allow DEBUG level messages to pass through the logger\n",
        "    force=True\n",
        ")\n",
        "\n",
        "logging.info(\"Starting\")\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "    logging.info(f\"{num_steps=}\")\n",
        "    logging.info(f\"{metrics=}\")\n",
        "\n",
        "    for key, value in metrics.items():\n",
        "      if isinstance(value, jp.ndarray):\n",
        "        metrics[key] = jax.device_put(value, cpu_device)\n",
        "    \n",
        "    wandb.log(metrics, step=num_steps)\n",
        "\n",
        "\n",
        "# @gin.configurable\n",
        "def training_main(\n",
        "        env_name: str,\n",
        "        backend: str,\n",
        "        experiment_name: str,\n",
        "        log_store_dir: str,\n",
        "        train_config: dict,\n",
        "):\n",
        "    exp_dir = f\"{log_store_dir}/{experiment_name}/{env_name}\"\n",
        "    Path(exp_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    seed = train_config.get(\"seed\")\n",
        "    env = envs.get_environment(env_name=env_name,\n",
        "                               backend=backend)\n",
        "    train_fn = functools.partial(\n",
        "        ppo.train,\n",
        "        **train_config,\n",
        "    )\n",
        "\n",
        "    # no way to save intermediate params, only at very end\n",
        "    make_inference_fn, params, _ = train_fn(\n",
        "        environment=env,\n",
        "        progress_fn=progress,\n",
        "    )\n",
        "    model.save_params(f\"{exp_dir}/params.pickle\", params)\n",
        "    wandb.save(exp_dir)\n",
        "    return env_name, backend, make_inference_fn, params\n",
        "\n",
        "\n",
        "def eval_main(\n",
        "    env_name,\n",
        "    backend,\n",
        "    make_inference_fn,\n",
        "    params,\n",
        "):\n",
        "    env = envs.get_environment(env_name=env_name, backend=backend)\n",
        "    inference_fn = make_inference_fn(params)\n",
        "    jit_env_reset = jax.jit(env.reset)\n",
        "    jit_env_step = jax.jit(env.step)\n",
        "    jit_inference_fn = jax.jit(inference_fn)\n",
        "    for rollout_idx in range(10):\n",
        "        logging.info(f\"{rollout_idx=}\")\n",
        "        rollout = []\n",
        "        rng = jax.random.PRNGKey(seed=rollout_idx)\n",
        "        state = jit_env_reset(rng=rng)\n",
        "        act_rng, rng = jax.random.split(rng)\n",
        "        done = False\n",
        "        while not done:\n",
        "            act, _ = jit_inference_fn(state.obs, act_rng)\n",
        "            state = jit_env_step(state, act)\n",
        "            rollout.append(state.pipeline_state)\n",
        "            done = state.done.any()\n",
        "        logging.info(f\"{rollout_idx=} {len(rollout)=}\")\n",
        "        # TODO bzs save render to json\n",
        "        wandb.Html(html.render(env.sys.replace(dt=env.dt), rollout))\n",
        "\n",
        "\n",
        "\n",
        "wandb_init(\n",
        "  project=\"timewise\",\n",
        "  entity = \"e1even\",\n",
        "  mode=\"online\",\n",
        "  name=\"humanoid_ppo_trial\",\n",
        "  config = train_config\n",
        ")\n",
        "try:\n",
        "    env_name, backend, make_inference_fn, params = training_main(\n",
        "      env_name = \"humanoid\",\n",
        "      backend =  \"generalized\",\n",
        "      experiment_name = \"humanoid\",\n",
        "      log_store_dir = \"humanoid\",\n",
        "      train_config = train_config)\n",
        "    eval_main(env_name, backend, make_inference_fn, params)\n",
        "except KeyboardInterrupt:\n",
        "    logging.warning(\"user quit\")\n",
        "finally:\n",
        "    wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}